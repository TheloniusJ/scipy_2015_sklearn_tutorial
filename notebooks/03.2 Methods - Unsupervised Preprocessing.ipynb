{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example from Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PCA to Plot Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is a useful preprocessing technique for both visualizing data in 2 or 3 dimensions, and for improving the performance of downstream algorithms such as classifiers. We will see more details about using PCA as part of a machine learning pipeline in the net section, but here we will explore the intuition behind what PCA does, and why it is useful for certain tasks.\n",
    "\n",
    "The goal of PCA is to find the dimensions of maximum variation in the data, and project onto them. This is helpful for data that is stretched in a particular dimension. Here we show an example in two dimensions, to get an understanding for how PCA can help classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "random_state = np.random.RandomState(1999)\n",
    "X = np.random.randn(500, 2)\n",
    "red_idx = np.where(X[:, 0] < 0)[0]\n",
    "blue_idx = np.where(X[:, 0] >= 0)[0]\n",
    "# Stretching\n",
    "s_matrix = np.array([[1, 0],\n",
    "                     [0, 20]])\n",
    "# Rotation\n",
    "r_angle = 33\n",
    "r_rad = np.pi * r_angle / 180\n",
    "r_matrix = np.array([[np.cos(r_rad), -np.sin(r_rad)],\n",
    "                    [np.sin(r_rad), np.cos(r_rad)]])\n",
    "\n",
    "X = np.dot(X, s_matrix).dot(r_matrix) \n",
    "plt.scatter(X[red_idx, 0], X[red_idx, 1], color=\"darkred\")\n",
    "plt.scatter(X[blue_idx, 0], X[blue_idx, 1], color=\"steelblue\")\n",
    "\n",
    "# Fix axes to show mismatched dimensions\n",
    "plt.axis('off')\n",
    "plt.title(\"Skewed Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X_t = pca.fit_transform(X)\n",
    "plt.scatter(X_t[red_idx, 0], X_t[red_idx, 1], color=\"darkred\")\n",
    "plt.scatter(X_t[blue_idx, 0], X_t[blue_idx, 1], color=\"steelblue\")\n",
    "plt.axis('off')\n",
    "plt.title(\"PCA Corrected Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use PCA to visualize complex data in low dimensions in order to see how \"close\" and \"far\" different datapoints are in a 2D space. There are many different ways to do this visualization, and some common algorithms are found in sklearn.manifold. PCA is one of the simplest and most common methods for quickly visualizing a dataset, and here we show its usefulness for the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Taken from example in scikit-learn examples\n",
    "# Authors: Fabian Pedregosa <fabian.pedregosa@inria.fr>\n",
    "#          Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#          Mathieu Blondel <mathieu@mblondel.org>\n",
    "#          Gael Varoquaux\n",
    "# License: BSD 3 clause (C) INRIA 2011\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble, lda,\n",
    "                     random_projection)\n",
    "\n",
    "digits = datasets.load_digits(n_class=6)\n",
    "n_digits = 500\n",
    "X = digits.data[:n_digits]\n",
    "y = digits.target[:n_digits]\n",
    "n_samples, n_features = X.shape\n",
    "n_neighbors = 30\n",
    "\n",
    "def plot_embedding(X, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(digits.target[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    if hasattr(offsetbox, 'AnnotationBbox'):\n",
    "        # only print thumbnails with matplotlib > 1.0\n",
    "        shown_images = np.array([[1., 1.]])  # just something big\n",
    "        for i in range(X.shape[0]):\n",
    "            dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < 4e-3:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.r_[shown_images, [X[i]]]\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n",
    "                X[i])\n",
    "            ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "n_img_per_row = 10\n",
    "img = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))\n",
    "for i in range(n_img_per_row):\n",
    "    ix = 10 * i + 1\n",
    "    for j in range(n_img_per_row):\n",
    "        iy = 10 * j + 1\n",
    "        img[ix:ix + 8, iy:iy + 8] = X[i * n_img_per_row + j].reshape((8, 8))\n",
    "\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('A selection from the 64-dimensional digits dataset')\n",
    "\n",
    "print(\"Computing PCA projection\")\n",
    "X_pca = decomposition.TruncatedSVD(n_components=2).fit_transform(X)\n",
    "plot_embedding(X_pca, \"Principal Components projection of the digits\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll take a look at unsupervised learning on a facial recognition example.\n",
    "This uses a dataset available within scikit-learn consisting of a\n",
    "subset of the [Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/)\n",
    "data.  Note that this is a relatively large download (~200MB) so it may\n",
    "take a while to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "lfw_people = datasets.fetch_lfw_people(min_faces_per_person=70, resize=0.4,\n",
    "                                       data_home='datasets')\n",
    "lfw_people.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're on a unix-based system such as linux or Mac OSX, these shell commands\n",
    "can be used to see the downloaded dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!du -sh datasets/lfw_home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize these faces to see what we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "# plot several images\n",
    "for i in range(15):\n",
    "    ax = fig.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(lfw_people.images[i], cmap=plt.cm.bone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a typical train-test split on the images before performing unsupervised learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(lfw_people.data, lfw_people.target, random_state=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Reduction Using Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use PCA to reduce the original 1850 features of the face images to a manageable\n",
    "size, while maintaining most of the information in the dataset.  Here it is useful to use a variant\n",
    "of PCA called ``RandomizedPCA``, which is an approximation of PCA that can be much faster for large\n",
    "datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.RandomizedPCA(n_components=150, whiten=True)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting part of PCA is that it computes the \"mean\" face, which can be\n",
    "interesting to examine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(pca.mean_.reshape((50, 37)), cmap=plt.cm.bone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principal components measure deviations about this mean along orthogonal axes.\n",
    "It is also interesting to visualize these principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(pca.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "for i in range(30):\n",
    "    ax = fig.add_subplot(3, 10, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(pca.components_[i].reshape((50, 37)), cmap=plt.cm.bone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components (\"eigenfaces\") are ordered by their importance from top-left to bottom-right.\n",
    "We see that the first few components seem to primarily take care of lighting\n",
    "conditions; the remaining components pull out certain identifying features:\n",
    "the nose, eyes, eyebrows, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this projection computed, we can now project our original training\n",
    "and test data onto the PCA basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_train_pca.shape)\n",
    "print(X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These projected components correspond to factors in a linear combination of\n",
    "component images such that the combination approaches the original face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
